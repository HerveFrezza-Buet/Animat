\documentclass[10pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage{xspace}
\usepackage[colorlinks=true, linkcolor=blue, anchorcolor=blue, citecolor=blue, filecolor=blue, menucolor=blue,
pagecolor=blue, urlcolor=blue]{hyperref}
\usepackage{graphicx}
\usepackage[margin=3cm]{geometry}
\usepackage{amsmath}

\newcommand{\Ou}[0]{\vee}
\newcommand{\Et}[0]{\wedge}
\newcommand{\Fx}     [2]{{#1} \left( #2                 \right)}
\newcommand{\Fxx}    [3]{{#1} \left( #2, #3             \right)}
\newcommand{\Fxxx}   [4]{{#1} \left( #2, #3, #4         \right)}
\newcommand{\Fxxxx}  [5]{{#1} \left( #2, #3, #4, #5     \right)}
\newcommand{\Fxxxxx} [6]{{#1} \left( #2, #3, #4, #5, #6 \right)}
\newcommand{\True}[0]{\mathtt{true}}
\newcommand{\False}[0]{\mathtt{false}}
\newcommand{\Diff}[1]{{\Delta #1}}
\newcommand{\diff}[1]{{\delta #1}}
\newcommand{\AttrOf}[2]{{#1}.\mathrm{#2}}
\newcommand{\Xof}[1]{\AttrOf{#1}x}
\newcommand{\Yof}[1]{\AttrOf{#1}y}
\newcommand{\Group}[1]{{\left({#1}\right)}}
\newcommand{\Pair}[2]{\left({#1},{#2}\right)}
\newcommand{\Set}[1]{\left\{ {#1} \right\}}
\newcommand{\At}[2]{#1_{#2}}
\newcommand{\AtT}[1]{\At{#1}t}
\newcommand{\Sat}[1]{{\left[{#1}\right]}^1_0}
\newcommand{\CamIn}[0]{\mathrm{Cam}}
\newcommand{\LgnIn}[0]{\mathrm{LGN}}
\newcommand{\Attent}[0]{\mathrm{Att}}
\newcommand{\Interest}[0]{\mathrm{C}}
\newcommand{\Focus}[0]{\mathrm{F}}
\newcommand{\Color}[3]{\mathrm{Col}_{#1,#2,#3}}
\newcommand{\Hydro}[0]{\mathrm{H}}
\newcommand{\Glyco}[0]{\mathrm{G}}
\newcommand{\Twist}[0]{{\cal T}}
\newcommand{\Ingest}[0]{\mathrm{Ing}}
\newcommand{\HIngest}[0]{\Hydro^{\mathrm{in}}}
\newcommand{\GIngest}[0]{\Glyco^{\mathrm{in}}}
\newcommand{\Ing}[0]{\delta}
\newcommand{\HIn}[0]{\Ing_\Hydro}
\newcommand{\GIn}[0]{\Ing_\Glyco}
\newcommand{\PhysioDecay}[0]{\tau}
\newcommand{\Htol}[0]{\mu}
\newcommand{\Vmin}[0]{\nu}
\newcommand{\Linear}{\mathrm{lin}}
\newcommand{\Angular}{\mathrm{ang}}
\newcommand{\AngularMax}[0]{\alpha}
\newcommand{\LinearMax}[0]{\lambda}
\newcommand{\Card}[1]{\left| {#1} \right|}
\newcommand{\Cart}[0]{\times}
\newcommand{\Discr}[1]{\widehat{#1}}
\newcommand{\Avg}[1]{\overline{#1}}
\newcommand{\Label}[1]{\mathtt{#1}}
\newcommand{\Left}[0]{\Label{left}}
\newcommand{\Middle}[0]{\Label{middle}}
\newcommand{\Right}[0]{\Label{right}}
\newcommand{\Far}[0]{\Label{far}}
\newcommand{\Near}[0]{\Label{near}}
\newcommand{\Comfort}[0]{\Label{comfort}}
\newcommand{\Shortage}[0]{\Label{shortage}}
\newcommand{\Go}[0]{\Label{go}}
\newcommand{\Stop}[0]{\Label{stop}}
\newcommand{\TurnLeft}[0]{\Label{turn\_left}}
\newcommand{\TurnRight}[0]{\Label{turn\_right}}
\newcommand{\Red}[0]{\Label{red}}
\newcommand{\Blue}[0]{\Label{blue}}
\newcommand{\FxThresh}[0]{\beta}
\newcommand{\FyThresh}[0]{\beta'}
\newcommand{\PhysioThresh}[0]{\varphi}
\newcommand{\FocusThresh}[0]{\xi}
\newcommand{\ObsSet}{{\cal O}}
\newcommand{\Obs}{o}
\newcommand{\ActionSet}{{\cal A}}
\newcommand{\Act}{a}
\newcommand{\Rew}{r}

\begin{document}

\hrule
\vspace{10mm}
\centerline{\LARGE Formalisation of the survival task}
\vspace{10mm}
\hrule
\vspace{10mm}

\tableofcontents

\section{The robot}

The robot evolves in a flat green environment. Some area are painted on the floor with a blue or red color. These are respective water and food areas. In the following, the time is denoted by $t$. Interactions between the robot and the world, i.e input acquisition and action execution, is performed every $\Diff t$ seconds. 

\subsection{Robot sensors}

The robot sees the world through a fixed front camera. The image is a colored image named $\CamIn$, pixels coordinates are in $[-.5,.5]^2$ (even if the real image is of course a discrete grid of colored pixels), such as the image width is $1$. The robot can move an attention point, i.e. a focus, into the current video image. The position of the focus is denoted by $\AtT\Focus = \Pair{\AtT{\Xof\Focus}}{\AtT{\Yof\Focus}} \in [-.5,.5]^2$.

Around the focus of attention, a distorted local view of the visual input is computed as a second colored image, denoted by $\LgnIn$, where pixels coordinates are in $[-.5,.5]^2$ as well. This image is turned into a Boolean image denoted by $\Attent$ (the attentional input) thanks to a color filter. The color filter will be denoted by the function $\Color hsv$ defined by equation~\ref{eq:color}, where $\Group{h,s,v}$ is the color to be detected. Thus $\AtT\Attent = \Fx {\Color hsv}{\AtT\LgnIn}$.

\begin{equation}
\Fx {\Color hsv}{c} = \Group{\AttrOf ch \in [h-\Htol,h+\Htol]} \Et \Group{\AttrOf cv > \Vmin \label{eq:color}}
\end{equation}

Last, an artificial physiology is implemented at the level of the robot. It consists of two scalar variables, $\AtT\Hydro \in [0,1]$ and $\AtT\Glyco \in [0,1]$, which represent respectively hydration and glycemia. Those physiological variables decay over time, except if they are refilled by external inputs from the world, respectively $\AtT\HIngest \in [0,1]$ and $\AtT\GIngest \in [0,1]$. The evolution of the physiology can be something like equation~\ref{eq:physio}, where $\Sat x = \max(\min(1,x),0)$. The formalism here is a discrete update from one time sample to the next, rather than a differential equation.

\begin{equation}
\At \Hydro {t+\Diff t} =  \Sat{\PhysioDecay_\Hydro\AtT\Hydro + \AtT\HIngest}, 
\;\At \Glyco {t+\Diff t} = \Sat{\PhysioDecay_\Glyco\AtT\Glyco + \AtT\GIngest} \label{eq:physio}
\end{equation}

To sum up, the robot sensor signals are $\Set{\AtT\Hydro,\AtT\Glyco,\AtT\CamIn,\AtT\Attent,\AtT\Focus}$.

\subsection{Robot actuators}

\subsubsection{Implicit actuators}

The focus of attention on the input image $\CamIn$ is driven by a reflex, which is based on $\AtT\Attent$. Indeed, if some $\True$ pixels lie in $\AtT\Attent$, the focus is moved such as the patch of such pixels gets centered on $\AtT\Attent$. This is driven by a neural field, not detailed here. 

\subsubsection{Explicit actuators}

First actuator is the selection of some color of interest. It consists of producing a signal $\AtT\Interest \in [0,1]^3$ corresponding to the HSV parameter given to the color filter. 
So $\AtT\Attent = \Fx {\Color {\AtT{\AttrOf\Interest h}}{\AtT{\AttrOf\Interest s}}{\AtT{\AttrOf\Interest v}}}{\AtT\LgnIn}$.

Second actuator is a velocity twist for the robot motion, denoted by 
\[
\AtT\Twist = \Pair {\AtT{\AttrOf\Twist\Linear}}{\AtT{\AttrOf\Twist\Angular}} \in [0,\LinearMax]\Cart[-\AngularMax,\AngularMax]
\]


Third actuator is the ingestion, which is a boolean signal $\AtT \Ingest \in \Set{\True,\False}$. It allows to compute inputs for glycemia and hydration.
\begin{equation}
\Pair{\AtT \HIngest}{\AtT \GIngest} = \left\{\begin{array}{ll}
\Pair 0 \GIn & \mbox{if } \AtT\Ingest = \True \mbox{ and the robot is in a red area} \\
\Pair \HIn 0 & \mbox{if } \AtT\Ingest = \True \mbox{ and the robot is in a blue area} \\
\Pair 00 & \mbox{otherwise}
\end{array}\right.
\end{equation}

To sum up, the robot actuator signals are $\Set{\AtT\Interest,\AtT\Twist,\AtT\Ingest}$


\section{Discretizing}

For further use in reinforcement learning, we need to discretize the signals. The notation $\Discr s$ recalls that $s$ is a signal with discrete values.

\subsection{Discrete sensors}

Let us define the discrete signals corresponding to the focus position as
\begin{equation}
\AtT {\Discr{\Xof\Focus}} = \left\{\begin{array}{ll}
\Left & \mbox{if } \AtT{\Xof\Focus} < -\FxThresh \\
\Right & \mbox{if } \AtT{\Xof\Focus} > \FxThresh \\
\Middle & \mbox{otherwise}
\end{array}\right.,\; 
\AtT {\Discr{\Yof\Focus}} = \left\{\begin{array}{ll}
\Near & \mbox{if } \AtT{\Xof\Focus} < \FyThresh \\
\Far & \mbox{otherwise}
\end{array}\right.
\end{equation}


The physiological variable are roughly discretized as well:
\begin{equation}
\AtT {\Discr{\Hydro}} = \left\{\begin{array}{ll}
\Comfort & \mbox{if } \AtT\Hydro > \PhysioThresh \\
\Shortage & \mbox{otherwise}
\end{array}\right.,\; 
\AtT {\Discr{\Glyco}} = \left\{\begin{array}{ll}
\Comfort & \mbox{if } \AtT\Glyco > \PhysioThresh \\
\Shortage & \mbox{otherwise}
\end{array}\right.
\end{equation}

For the visual input, we only rely on $\Attent$. We compute a signal from it, telling whether there is something seen or not. Remember that when something is present in $\Attent$, it is implicitly focused on. Thus, let us denote by $\AtT {\Avg\Attent}$ the ratio of $\True$ pixels in $\AtT\Attent$. We can define the discrete information got from the focus point as $\AtT {\Discr\Attent} = \AtT {\Avg\Attent}>\FocusThresh$.

Let us denote by $\AtT \Obs \in \ObsSet$ the current discretized sensor information available to the robot. The following stands:
\begin{eqnarray}
\AtT \Obs &=& \Group{\AtT {\Discr{\Xof\Focus}}, \AtT {\Discr{\Yof\Focus}}, \AtT {\Discr{\Hydro}}, \AtT {\Discr{\Glyco}},\AtT {\Discr\Attent}} \\
\ObsSet &=& \Set{\Label{\Left},\Label{\Middle},\Label{\Right}}\times\Set{\Label{\Near},\Label{\Far}}
\times\Set{\Label{\Comfort},\Label{\Shortage}}^2\times\Set{\True,\False} \\
\Card \ObsSet &=& 3\times 2\times 2\times 2\times  2  = 48
\end{eqnarray}

\subsection{Discrete actuators}

Let us define four discrete twists, such as $\AtT{\Discr\Twist} \in \Set{\Go,\Stop,\TurnLeft,\TurnRight}$, where $\Go = \Pair \LinearMax 0, \Stop = \Pair 00, \TurnLeft = \Pair 0\AngularMax, \TurnRight = \Pair 0{-\AngularMax}$.

Apart from robot motion, actuators are ingestion $\AtT\Ingest$, which is by definition a discrete signal already, and also the choice of the color for the filter. Let us use only two colors, so that $\AtT{\Discr\Interest} \in \Set{\Blue,\Red}$, where $\Blue = \Group{h_\Blue,1,1}$ and $\Red = \Group{h_\Red,1,1}$.

To sum up, the action $\AtT\Act \in \ActionSet$ is such as:
\begin{eqnarray}
\AtT \Act &=& \Group{\AtT{\Discr\Twist},\AtT\Ingest,\AtT{\Discr\Interest}} \\
\ActionSet &=& \Set{\Go,\Stop,\TurnLeft,\TurnRight} \times \Set{\True,\False} \times  \Set{\Blue,\Red} \\
\Card \ActionSet &=& 4\times 2\times 2 = 16
\end{eqnarray}

\section{Toward reinforcement learning}

\subsection{From time to events}

Let us denote by $u$ the time used in RL. RL time is rather called a step in the following. When performing an action at step$u$, the controlled system goes to next step $u+1$. Let us stress here that $t$ and $u$ are fundamentally different. The problem for applying RL is to identify the succession of steps in the behaviour ($u,u+1,u+2,\cdots$) while real-life time is sampled as $t,t+\Diff t, t+2\Diff t,\cdots$ that may not match steps!

The same stands for actions. Even if they are discrete, they need to start and end. For example, action $\TurnLeft$ is an elementary rotation, i.e. the twist $\TurnLeft$ applied during a certain duration. After that duration, the action $\TurnLeft$ performed at step $u$ is considered to be performed, and the controller skips to next step $u+1$.

Such consideration require to set up events, allowing to identify steps $u$ from the temporal signals.

\subsection{States and action}

States have to be Markovian for applying the RL theory. Is $\Obs$ a Markovian representation that a controller should rely on for playing the role of states~? Let us answer positively for first implementations.

\subsection{Reward}

Reward is a hard-wired process telling the robot what it is supposed to do, since the behavior computed by RL is the one that maximized the accumulation of rewards\footnote{A $\gamma$-discounted accumulation indeed.} along the robot's life. Reward is provided after each transition from step $u$ to $u+1$, it thus requires an event-based implementation as well. For example, we could consider the reward signal $\AtT \Rew$ as follows:
\begin{equation}
\AtT \Rew = \left\{\begin{array}{ll}
-1 & \mbox{if } \AtT {\Discr{\Hydro}} = \Comfort \mbox{ and } \AtT {\Discr{\Glyco}} = \Shortage \\
-1 & \mbox{if } \AtT {\Discr{\Hydro}} = \Shortage \mbox{ and } \AtT {\Discr{\Glyco}} = \Comfort \\
-2 & \mbox{if } \AtT {\Discr{\Hydro}} = \Shortage \mbox{ and } \AtT {\Discr{\Glyco}} = \Shortage \\
0 & \mbox{otherwise}
\end{array}\right.
\end{equation}

\end{document}
